{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1f6XBubqzqBxAfNsHqF7A6TV3QwTtpH55",
      "authorship_tag": "ABX9TyPuKfKk+Qg3RLvbpp0tpftv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/audreychristensen/Bird_Audio_CNN/blob/main/2.1%20Model%20for%20Subset%20of%20Species.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import IPython.display as ipd\n",
        "from PIL import Image\n",
        "\n",
        "import soundfile as sf\n",
        "import scipy.io.wavfile as wave\n",
        "import scipy.ndimage as ndimage\n",
        "import scipy.stats as stats\n",
        "from scipy import interpolate\n",
        "import traceback\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "N-QW2S2Y1w9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/F2024/Applied Data Science/Project 3/'"
      ],
      "metadata": {
        "id": "8ShJwx9fffgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hdf5_path = base_dir + 'output_spectrograms_final.h5'\n",
        "birds_df = pd.read_csv(base_dir + 'bird_dict.csv')"
      ],
      "metadata": {
        "id": "qx3lmFjmfzEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bird_dict = dict(zip(birds_df.iloc[:, 0], birds_df.iloc[:, 1]))"
      ],
      "metadata": {
        "id": "MZOXxt7mf2Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_aqHv5z-YQq"
      },
      "outputs": [],
      "source": [
        "# Set runtime to GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "7dO1_jz9fwlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define"
      ],
      "metadata": {
        "id": "3eoGWT__f8ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BirdSpectrogramDataset(Dataset):\n",
        "    def __init__(self, hdf5_path, bird_dict, transform=None):\n",
        "        self.hdf5_path = hdf5_path\n",
        "        self.bird_dict = bird_dict\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "\n",
        "        with h5py.File(hdf5_path, 'r') as f:\n",
        "            # Iterate through all groups (bird species)\n",
        "            for species_name, species_group in f.items():\n",
        "                    species_label = bird_dict.get(species_name, -1)  # Get label from dictionary\n",
        "                    # Loop through spectrograms in each species group\n",
        "                    for spectrogram in species_group.values():\n",
        "                        self.data.append(spectrogram[()])\n",
        "                        self.labels.append(species_label)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        spectrogram = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            spectrogram = self.transform(spectrogram)\n",
        "\n",
        "        return spectrogram, label\n"
      ],
      "metadata": {
        "id": "Zs13pFivLOSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # You can adjust this if needed\n",
        "])"
      ],
      "metadata": {
        "id": "P-jS6TlBLOQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = BirdSpectrogramDataset(hdf5_path, bird_dict, transform=transform)\n",
        "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, stratify=dataset.labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "upHn2fSBLOOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 32 * 64, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 128 * 32 * 64)  # Flattening\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "oIvLOlkNLOLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(bird_dict)\n",
        "model = CNNModel(num_classes).to(device)"
      ],
      "metadata": {
        "id": "Y5rF2B2OLOI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "3gXCBD9FLOGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "CcWV4A9pf_0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfyUQBbsLOEO",
        "outputId": "d7d656bb-e4b1-4097-8eae-1dc7b75ce02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.1863, Accuracy: 93.76%\n",
            "Epoch [2/10], Loss: 0.1025, Accuracy: 97.41%\n",
            "Epoch [3/10], Loss: 0.1309, Accuracy: 96.20%\n",
            "Epoch [4/10], Loss: 0.1098, Accuracy: 96.34%\n",
            "Epoch [5/10], Loss: 0.0810, Accuracy: 98.00%\n",
            "Epoch [6/10], Loss: 0.0691, Accuracy: 97.56%\n",
            "Epoch [7/10], Loss: 0.0343, Accuracy: 98.83%\n",
            "Epoch [8/10], Loss: 0.0243, Accuracy: 99.32%\n",
            "Epoch [9/10], Loss: 0.0277, Accuracy: 99.12%\n",
            "Epoch [10/10], Loss: 0.0719, Accuracy: 98.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Validate"
      ],
      "metadata": {
        "id": "n44NqHV9gDJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "val_accuracy = 100 * correct / total\n",
        "print(f'Validation Accuracy: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCI7PnIRLOB5",
        "outputId": "aa57c7b6-6df5-4c26-816e-698c6fc3ffab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 67.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation Accuracy per Species:"
      ],
      "metadata": {
        "id": "1eWdEI00gIIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "species_correct = {species: 0 for species in bird_dict.keys()}\n",
        "species_total = {species: 0 for species in bird_dict.keys()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Track correct and total for each species\n",
        "        for i in range(labels.size(0)):\n",
        "            species_name = list(bird_dict.keys())[list(bird_dict.values()).index(labels[i].item())]\n",
        "            species_total[species_name] += 1\n",
        "            if predicted[i] == labels[i]:\n",
        "                species_correct[species_name] += 1\n",
        "\n",
        "val_accuracy = 100 * correct / total\n",
        "print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "# Calculate and print % of correct classifications per species\n",
        "print(\"\\nPercentage of Correct Classifications per Species:\")\n",
        "for species in bird_dict.keys():\n",
        "    species_accuracy = 100 * species_correct[species] / species_total[species] if species_total[species] > 0 else 0\n",
        "    print(f\"Species: {species}, Correct: {species_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH8wUAUcLN_i",
        "outputId": "9e2e7b74-a75e-4854-ddc1-6b2535bf70a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 67.25%\n",
            "\n",
            "Percentage of Correct Classifications per Species:\n",
            "Species: AmericanCrow, Correct: 81.82%\n",
            "Species: AmericanRedstart, Correct: 69.61%\n",
            "Species: AmericanRobin, Correct: 78.00%\n",
            "Species: AmericanYellowWarbler, Correct: 41.18%\n",
            "Species: BarnSwallow, Correct: 65.42%\n",
            "Species: noise, Correct: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_species = {v: k for k, v in bird_dict.items()}"
      ],
      "metadata": {
        "id": "O0cdC-u5UxdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('class_to_species.pkl', 'wb') as f:\n",
        "    pickle.dump(class_to_species, f)"
      ],
      "metadata": {
        "id": "L8gT3F-cUx7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), base_dir + 'full_bird_model.pth')"
      ],
      "metadata": {
        "id": "19rbFRxRLN87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we try to predict a bird from a full length recording! I will be using a recording >1 minute long because it is easy for me to know that that didn't make it into our training data"
      ],
      "metadata": {
        "id": "qfDPkhd-RA-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getMelSpec(path, seconds = 5, overlap = 4, minlen = 3, winlen=0.05, winstep=0.0097, NFFT=840, sr_target=44100):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  y, sr = librosa.load(path, sr=sr_target)\n",
        "  print(f\"shape: {y.shape}\", f'sr: {sr}')\n",
        "  sig_splits = []\n",
        "  step = int((seconds - overlap) * sr)\n",
        "  window_length = int(seconds * sr)\n",
        "  NFFT = max(NFFT, int(winlen * sr))\n",
        "\n",
        "  for i in range(0, len(y), step):\n",
        "    split =  y[i:i + window_length]\n",
        "    if len(split) >= minlen:\n",
        "      sig_splits.append(split)\n",
        "\n",
        "  if len(sig_splits) == 0:\n",
        "    sig_splits.append(sig)\n",
        "\n",
        "\n",
        "  for split_sig in sig_splits:\n",
        "        # compute mel spectrogram\n",
        "        mel_spec = librosa.feature.melspectrogram(\n",
        "            y=split_sig,\n",
        "            sr=sr,\n",
        "            n_fft=int(winlen * sr),\n",
        "            hop_length=int(winstep * sr),\n",
        "            n_mels=128*2\n",
        "        )\n",
        "\n",
        "        # Convert to dB scale\n",
        "        mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "        # resize to fixed shape\n",
        "        mel_spec_resized = cv2.resize(mel_spec_db, (512, 256))\n",
        "\n",
        "        yield mel_spec_resized\n",
        "\n",
        "def filter_isolated_cells(array, struct):\n",
        "\n",
        "    filtered_array = np.copy(array)\n",
        "    id_regions, num_ids = ndimage.label(filtered_array, structure=struct)\n",
        "    id_sizes = np.array(ndimage.sum(array, id_regions, range(num_ids + 1)))\n",
        "    area_mask = (id_sizes == 1)\n",
        "    filtered_array[area_mask[id_regions]] = 0\n",
        "\n",
        "    return filtered_array\n",
        "\n",
        "\n",
        "def hasBird(spec, threshold=16):\n",
        "\n",
        "    #working copy\n",
        "    img = spec.copy()\n",
        "\n",
        "    #STEP 1: Median blur\n",
        "    img = cv2.medianBlur(img,5)\n",
        "\n",
        "    #STEP 2: Median threshold\n",
        "    col_median = np.median(img, axis=0, keepdims=True)\n",
        "    row_median = np.median(img, axis=1, keepdims=True)\n",
        "\n",
        "    img[img < row_median * 3] = 0\n",
        "    img[img < col_median * 4] = 0\n",
        "    img[img > 0] = 1\n",
        "\n",
        "    #STEP 3: Remove singles\n",
        "    img = filter_isolated_cells(img, struct=np.ones((3,3)))\n",
        "\n",
        "    #STEP 4: Morph Closing\n",
        "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5,5), np.float32))\n",
        "\n",
        "    #STEP 5: Frequency crop\n",
        "    img = img[128:-16, :]\n",
        "\n",
        "    #STEP 6: Count columns and rows with signal\n",
        "    #(Note: We only use rows with signal as threshold, but columns might come in handy in other scenarios)\n",
        "\n",
        "    #column has signal?\n",
        "    col_max = np.max(img, axis=0)\n",
        "    col_max = ndimage.morphology.binary_dilation(col_max, iterations=2).astype(col_max.dtype)\n",
        "    cthresh = col_max.sum()\n",
        "\n",
        "    #row has signal?\n",
        "    row_max = np.max(img, axis=1)\n",
        "    row_max = ndimage.morphology.binary_dilation(row_max, iterations=2).astype(row_max.dtype)\n",
        "    rthresh = row_max.sum()\n",
        "\n",
        "    #final threshold\n",
        "    thresh = rthresh\n",
        "\n",
        "    #DBUGB: show?\n",
        "    #print thresh\n",
        "    #cv2.imshow('BIRD?', img)\n",
        "    #cv2.waitKey(-1)\n",
        "\n",
        "    #STEP 7: Apply threshold (Default = 16)\n",
        "    bird = True\n",
        "    if thresh < threshold:\n",
        "        bird = False\n",
        "\n",
        "    return bird, thresh"
      ],
      "metadata": {
        "id": "TBsPc3y0RLyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bird = '/content/drive/MyDrive/F2024/Applied Data Science/Project 3/bird_calls_highest_quality/AmericanRobin/543354.mp3'"
      ],
      "metadata": {
        "id": "M-jAvAheSLWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectrograms = list(getMelSpec(bird))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzmPyV6kRexS",
        "outputId": "fe379f3f-75b2-492d-c1bc-2add6606324a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (2840832,) sr: 44100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def spectrograms_to_tensor(spectrograms, device='cuda'):\n",
        "    spectrograms_tensor = torch.tensor(np.array(spectrograms)).unsqueeze(1).float().to(device)\n",
        "    return spectrograms_tensor\n",
        "\n",
        "def predict_from_spectrograms(model, spectrograms, device='cuda'):\n",
        "    spectrograms_tensor = spectrograms_to_tensor(spectrograms, device)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(spectrograms_tensor)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "spectrograms = list(getMelSpec(bird))\n",
        "predictions = predict_from_spectrograms(model, spectrograms, device='cuda')\n",
        "\n",
        "print(f'Predictions: {predictions}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95szHjwITZOO",
        "outputId": "d9e11d7e-2416-40ee-b256-cc78826e6a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (2840832,) sr: 44100\n",
            "Predictions: tensor([4, 4, 1, 3, 3, 3, 3, 5, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 3, 1, 5, 3,\n",
            "        5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "3gOlYf-pTd7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pjB0DhvBTyFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_frequent_species(predictions, class_to_species):\n",
        "    prediction_counts = Counter(predictions.cpu().numpy())\n",
        "\n",
        "    most_frequent_index = prediction_counts.most_common(1)[0][0]\n",
        "    most_frequent_count = prediction_counts.most_common(1)[0][1]\n",
        "\n",
        "    species = class_to_species[most_frequent_index]\n",
        "\n",
        "    confidence = (most_frequent_count / len(predictions)) * 100\n",
        "\n",
        "    return species, confidence, prediction_counts"
      ],
      "metadata": {
        "id": "LTfR-38kT0wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "species, confidence, prediction_counts = get_most_frequent_species(predictions, class_to_species)\n",
        "\n",
        "print(f'Most frequent species: {species} in {confidence:.2f}% of recording')\n",
        "print(f'Prediction counts: {prediction_counts}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnDEmT_JT3Ww",
        "outputId": "a0465980-8e1b-4615-ad0e-1fcdac0bd33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent species: AmericanRobin with 61.54% confidence\n",
            "Prediction counts: Counter({3: 40, 1: 14, 4: 8, 5: 3})\n"
          ]
        }
      ]
    }
  ]
}
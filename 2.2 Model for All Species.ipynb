{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Hb1H4vkWBu1m8298l2h-c24aYwPueUol",
      "authorship_tag": "ABX9TyOXXV/dlOdYdkaSrgJyUBfy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/audreychristensen/Bird_Audio_CNN/blob/main/2.1%20Model%20for%20All%20Species.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import IPython.display as ipd\n",
        "from PIL import Image\n",
        "\n",
        "import soundfile as sf\n",
        "import scipy.io.wavfile as wave\n",
        "import scipy.ndimage as ndimage\n",
        "import scipy.stats as stats\n",
        "from scipy import interpolate\n",
        "import traceback\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "N-QW2S2Y1w9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/F2024/Applied Data Science/Project 3/'"
      ],
      "metadata": {
        "id": "8ShJwx9fffgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hdf5_path = base_dir + 'output_spectrograms_final.h5'\n",
        "birds_df = pd.read_csv(base_dir + 'bird_dict.csv')"
      ],
      "metadata": {
        "id": "qx3lmFjmfzEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bird_dict = dict(zip(birds_df.iloc[:, 0], birds_df.iloc[:, 1]))"
      ],
      "metadata": {
        "id": "MZOXxt7mf2Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_aqHv5z-YQq"
      },
      "outputs": [],
      "source": [
        "# Set runtime to GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "7dO1_jz9fwlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b61d2f-cd11-4d93-ffe3-701461c079a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hdf5_paths = [base_dir + 'birds_data_2.h5', base_dir + 'birds_data_3.h5', base_dir + 'birds_data_4.h5', base_dir + 'birds_data_5.h5']"
      ],
      "metadata": {
        "id": "72LAnvJnNK_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define"
      ],
      "metadata": {
        "id": "3eoGWT__f8ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BirdSpectrogramDataset(Dataset):\n",
        "    def __init__(self, hdf5_paths, bird_dict, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hdf5_paths (list): List of paths to HDF5 files.\n",
        "            bird_dict (dict): Dictionary mapping bird species names to integer labels.\n",
        "            transform (callable, optional): Optional transform to apply to spectrograms.\n",
        "        \"\"\"\n",
        "        self.hdf5_paths = hdf5_paths\n",
        "        self.bird_dict = bird_dict\n",
        "        self.transform = transform\n",
        "        self.index_map = []  # To store (file_idx, group_name, spectrogram_key)\n",
        "\n",
        "        # Build an index of all spectrograms across files\n",
        "        for file_idx, hdf5_path in enumerate(hdf5_paths):\n",
        "            with h5py.File(hdf5_path, 'r') as f:\n",
        "                for species_name, species_group in f.items():\n",
        "                    species_label = bird_dict.get(species_name, -1)  # Get label from dictionary\n",
        "                    for spectrogram_key in species_group.keys():\n",
        "                        self.index_map.append((file_idx, species_name, spectrogram_key, species_label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_idx, species_name, spectrogram_key, label = self.index_map[idx]\n",
        "        hdf5_path = self.hdf5_paths[file_idx]\n",
        "\n",
        "        # Load spectrogram lazily from the corresponding HDF5 file\n",
        "        with h5py.File(hdf5_path, 'r') as f:\n",
        "            spectrogram = f[species_name][spectrogram_key][()]\n",
        "\n",
        "        if self.transform:\n",
        "            spectrogram = self.transform(spectrogram)\n",
        "\n",
        "        return spectrogram, label\n"
      ],
      "metadata": {
        "id": "Zs13pFivLOSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # You can adjust this if needed\n",
        "])"
      ],
      "metadata": {
        "id": "P-jS6TlBLOQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = BirdSpectrogramDataset(hdf5_paths, bird_dict, transform=transform)"
      ],
      "metadata": {
        "id": "nUXaFKyPPkPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "all_labels = []\n",
        "for hdf5_path in hdf5_paths:\n",
        "    with h5py.File(hdf5_path, 'r') as f:\n",
        "        for species_name, species_group in f.items():\n",
        "            species_label = bird_dict.get(species_name, -1)\n",
        "            all_labels.extend([species_label] * len(species_group))\n",
        "\n",
        "indices = list(range(len(all_labels)))\n",
        "train_indices, val_indices = train_test_split(\n",
        "    indices, test_size=0.2, stratify=all_labels\n",
        ")\n",
        "\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "rrvF4QCTPe7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Model (2.1)"
      ],
      "metadata": {
        "id": "-J7-0g_jOr26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 32 * 64, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 128 * 32 * 64)  # Flattening\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "oIvLOlkNLOLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(bird_dict)\n",
        "model = CNNModel(num_classes).to(device)"
      ],
      "metadata": {
        "id": "Y5rF2B2OLOI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "3gXCBD9FLOGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = base_dir + 'model_checkpoint.pth'"
      ],
      "metadata": {
        "id": "gC-VXLZfWo4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "    print(f'Model weights saved to {checkpoint_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfyUQBbsLOEO",
        "outputId": "a02eeae4-3307-4a91-e654-0c8ad34a738f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 6.1479, Accuracy: 1.26%\n",
            "Epoch [2/10], Loss: 4.3136, Accuracy: 1.30%\n",
            "Epoch [3/10], Loss: 4.3132, Accuracy: 1.33%\n",
            "Epoch [4/10], Loss: 4.3131, Accuracy: 1.39%\n",
            "Epoch [5/10], Loss: 4.3130, Accuracy: 1.36%\n",
            "Epoch [6/10], Loss: 4.3128, Accuracy: 1.37%\n",
            "Epoch [7/10], Loss: 4.3128, Accuracy: 1.31%\n",
            "Epoch [8/10], Loss: 4.3126, Accuracy: 1.42%\n",
            "Epoch [9/10], Loss: 4.3128, Accuracy: 1.32%\n",
            "Epoch [10/10], Loss: 4.3126, Accuracy: 1.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_batch_size = 64\n",
        "new_lr = 0.0005\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=new_batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=new_batch_size, shuffle=False)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=new_lr)"
      ],
      "metadata": {
        "id": "h_VHvORrbBJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "    print(f'Model weights saved to {checkpoint_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "VPkUSSZ8eZKX",
        "outputId": "02152a6f-e798-4442-9f01-d4ed501f9ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 4.3121, Accuracy: 1.33%\n",
            "Model weights saved to /content/drive/MyDrive/F2024/Applied Data Science/Project 3/model_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e141a6def168>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model w Updates (2.2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JEh_SLxAiWRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Increase fully connected layer sizes\n",
        "        self.fc1 = nn.Linear(256 * 16 * 32, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = self.pool(self.relu(self.conv4(x)))\n",
        "\n",
        "        x = x.view(-1, 256 * 16 * 32)  # Adjust flattening\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Vl4W4u0UiX2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(bird_dict)\n",
        "model2 = CNNModel(num_classes).to(device)"
      ],
      "metadata": {
        "id": "9hrFtZlMiaBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model2.parameters(), lr=0.0005)"
      ],
      "metadata": {
        "id": "-s0JLODRiiv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model2.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model2(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "    torch.save(model2.state_dict(), checkpoint_path)\n",
        "    print(f'Model weights saved to {checkpoint_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "m-g2e8eIjNfJ",
        "outputId": "f5d70be5-0484-46d0-cb8c-dfc1efde950b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 4.3687, Accuracy: 1.56%\n",
            "Model weights saved to /content/drive/MyDrive/F2024/Applied Data Science/Project 3/model_checkpoint.pth\n",
            "Epoch [2/5], Loss: 4.3097, Accuracy: 1.55%\n",
            "Model weights saved to /content/drive/MyDrive/F2024/Applied Data Science/Project 3/model_checkpoint.pth\n",
            "Epoch [3/5], Loss: 4.3130, Accuracy: 1.32%\n",
            "Model weights saved to /content/drive/MyDrive/F2024/Applied Data Science/Project 3/model_checkpoint.pth\n",
            "Epoch [4/5], Loss: 4.3128, Accuracy: 1.30%\n",
            "Model weights saved to /content/drive/MyDrive/F2024/Applied Data Science/Project 3/model_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-6b42bfde787a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further updates (2.3)"
      ],
      "metadata": {
        "id": "4fxRNVlBpCMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BirdClassifierCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(BirdClassifierCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        x = self.gap(x).view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n"
      ],
      "metadata": {
        "id": "I2XpYvpBpBxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "bqHgqxHmpUg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_path = base_dir + 'model_checkpoint_3.2.pth'\n",
        "optimizer_checkpoint_path = base_dir + 'optimizer_checkpoint_3.2.pth'\n",
        "scheduler_checkpoint_path = base_dir + 'scheduler_checkpoint_3.2.pth'"
      ],
      "metadata": {
        "id": "KxYVlS2epZXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(bird_dict)\n",
        "model = BirdClassifierCNN(num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "5tkGBA4CpEcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)  # Reinitialize scheduler"
      ],
      "metadata": {
        "id": "57UPr_ea5JuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "        # Save model weights after each epoch\n",
        "        torch.save(model.state_dict(), model_checkpoint_path)\n",
        "        torch.save(optimizer.state_dict(), optimizer_checkpoint_path)"
      ],
      "metadata": {
        "id": "eYnEEppBpMap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9b7593-a92d-4546-e153-35c54b654a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 4.1823, Accuracy: 3.60%\n",
            "Epoch [2/5], Loss: 3.9657, Accuracy: 6.67%\n",
            "Epoch [3/5], Loss: 3.7798, Accuracy: 9.79%\n",
            "Epoch [4/5], Loss: 3.6223, Accuracy: 12.79%\n",
            "Epoch [5/5], Loss: 3.4839, Accuracy: 15.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch = 10\n",
        "num_epochs = 20"
      ],
      "metadata": {
        "id": "ygXn553r5acw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(start_epoch, num_epochs):  # start_epoch is the epoch to resume from\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Step the scheduler after each epoch to adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "    # Save model weights, optimizer state, and scheduler state after each epoch\n",
        "    torch.save(model.state_dict(), model_checkpoint_path)\n",
        "    torch.save(optimizer.state_dict(), optimizer_checkpoint_path)\n",
        "    torch.save(scheduler.state_dict(), scheduler_checkpoint_path)  # Save scheduler state\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9hAaPCR5Suf",
        "outputId": "959d916a-09b9-44be-b9f7-c15a43a0dac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/20], Loss: 3.0158, Accuracy: 24.91%\n",
            "Epoch [12/20], Loss: 2.9576, Accuracy: 26.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Validate"
      ],
      "metadata": {
        "id": "n44NqHV9gDJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "val_accuracy = 100 * correct / total\n",
        "print(f'Validation Accuracy: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCI7PnIRLOB5",
        "outputId": "b90b4447-bc4a-4903-9fe7-08e05d70276b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 24.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation Accuracy per Species:"
      ],
      "metadata": {
        "id": "1eWdEI00gIIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "species_correct = {species: 0 for species in bird_dict.keys()}\n",
        "species_total = {species: 0 for species in bird_dict.keys()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Track correct and total for each species\n",
        "        for i in range(labels.size(0)):\n",
        "            species_name = list(bird_dict.keys())[list(bird_dict.values()).index(labels[i].item())]\n",
        "            species_total[species_name] += 1\n",
        "            if predicted[i] == labels[i]:\n",
        "                species_correct[species_name] += 1\n",
        "\n",
        "val_accuracy = 100 * correct / total\n",
        "print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "# Calculate and print % of correct classifications per species\n",
        "print(\"\\nPercentage of Correct Classifications per Species:\")\n",
        "for species in bird_dict.keys():\n",
        "    species_accuracy = 100 * species_correct[species] / species_total[species] if species_total[species] > 0 else 0\n",
        "    print(f\"Species: {species}, Correct: {species_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH8wUAUcLN_i",
        "outputId": "92ef695f-7db6-4512-d9a2-d681e2f86f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 24.27%\n",
            "\n",
            "Percentage of Correct Classifications per Species:\n",
            "Species: NorthernGoshawk, Correct: 3.96%\n",
            "Species: WaterPipit, Correct: 47.52%\n",
            "Species: PeregrineFalcon, Correct: 38.10%\n",
            "Species: HoodedWarbler, Correct: 85.85%\n",
            "Species: Ovenbird, Correct: 19.81%\n",
            "Species: HouseSparrow, Correct: 0.00%\n",
            "Species: WoodThrush, Correct: 23.30%\n",
            "Species: HouseWren, Correct: 12.62%\n",
            "Species: TundraSwan, Correct: 21.57%\n",
            "Species: HornedLark, Correct: 65.35%\n",
            "Species: Chestnut-sidedWarbler, Correct: 2.88%\n",
            "Species: Gull-billedTern, Correct: 9.28%\n",
            "Species: GreatEgret, Correct: 28.43%\n",
            "Species: Gadwall, Correct: 19.80%\n",
            "Species: CommonGoldeneye, Correct: 16.83%\n",
            "Species: GreatHornedOwl, Correct: 60.00%\n",
            "Species: LesserBlack-backedGull, Correct: 38.83%\n",
            "Species: NorthernCardinal, Correct: 17.92%\n",
            "Species: RedCrossbill, Correct: 65.14%\n",
            "Species: RoseateTern, Correct: 33.02%\n",
            "Species: GreatCormorant, Correct: 4.81%\n",
            "Species: Red-eyedVireo, Correct: 1.92%\n",
            "Species: WarblingVireo, Correct: 0.00%\n",
            "Species: Grey-hoodedWarbler, Correct: 6.60%\n",
            "Species: SavannahSparrow, Correct: 44.76%\n",
            "Species: Brown-headedCowbird, Correct: 3.92%\n",
            "Species: BarnSwallow, Correct: 28.30%\n",
            "Species: CommonMoorhen, Correct: 3.00%\n",
            "Species: NorthernFlicker, Correct: 0.00%\n",
            "Species: BlackTern, Correct: 52.34%\n",
            "Species: CommonTern, Correct: 3.92%\n",
            "Species: SongSparrow, Correct: 2.83%\n",
            "Species: Black-crownedNightHeron, Correct: 7.62%\n",
            "Species: HermitThrush, Correct: 38.61%\n",
            "Species: NorthernMockingbird, Correct: 16.83%\n",
            "Species: AmericanRobin, Correct: 1.00%\n",
            "Species: EasternMeadowlark, Correct: 12.62%\n",
            "Species: PineWarbler, Correct: 54.72%\n",
            "Species: BlueJay, Correct: 33.96%\n",
            "Species: EurasianWigeon, Correct: 0.00%\n",
            "Species: IndigoBunting, Correct: 0.99%\n",
            "Species: BarredOwl, Correct: 34.65%\n",
            "Species: NorthernWaterthrush, Correct: 17.14%\n",
            "Species: TuftedTitmouse, Correct: 0.00%\n",
            "Species: LaplandLongspur, Correct: 1.90%\n",
            "Species: EasternSubalpineWarbler, Correct: 30.10%\n",
            "Species: BlueGrosbeak, Correct: 9.52%\n",
            "Species: Dark-eyedJunco, Correct: 70.48%\n",
            "Species: EuropeanHerringGull, Correct: 1.96%\n",
            "Species: AmericanRedstart, Correct: 0.98%\n",
            "Species: Sanderling, Correct: 48.11%\n",
            "Species: RuddyTurnstone, Correct: 9.00%\n",
            "Species: MarshWren, Correct: 45.54%\n",
            "Species: White-crownedSparrow, Correct: 0.00%\n",
            "Species: Dunlin, Correct: 24.27%\n",
            "Species: Black-leggedKittiwake, Correct: 41.51%\n",
            "Species: Yellow-breastedChat, Correct: 3.88%\n",
            "Species: BrantGoose, Correct: 78.43%\n",
            "Species: Red-wingedBlackbird, Correct: 31.13%\n",
            "Species: EurasianWhimbrel, Correct: 31.43%\n",
            "Species: CarolinaWren, Correct: 25.69%\n",
            "Species: AmericanCrow, Correct: 42.42%\n",
            "Species: EasternTowhee, Correct: 14.85%\n",
            "Species: Mallard, Correct: 50.49%\n",
            "Species: CommonYellowthroat, Correct: 22.77%\n",
            "Species: Dickcissel, Correct: 20.00%\n",
            "Species: CaspianTern, Correct: 12.87%\n",
            "Species: GreatBlack-backedGull, Correct: 4.90%\n",
            "Species: HouseFinch, Correct: 16.19%\n",
            "Species: WesternOsprey, Correct: 20.79%\n",
            "Species: LittleGull, Correct: 47.47%\n",
            "Species: CommonSnipe, Correct: 16.36%\n",
            "Species: White-throatedSparrow, Correct: 61.39%\n",
            "Species: AmericanYellowWarbler, Correct: 2.94%\n",
            "Species: noise, Correct: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_species = {v: k for k, v in bird_dict.items()}"
      ],
      "metadata": {
        "id": "O0cdC-u5UxdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('class_to_species.pkl', 'wb') as f:\n",
        "    pickle.dump(class_to_species, f)"
      ],
      "metadata": {
        "id": "L8gT3F-cUx7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), base_dir + 'full_bird_model.pth')"
      ],
      "metadata": {
        "id": "19rbFRxRLN87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we try to predict a bird from a full length recording! I will be using a recording >1 minute long because it is easy for me to know that that didn't make it into our training data"
      ],
      "metadata": {
        "id": "qfDPkhd-RA-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getMelSpec(path, seconds = 5, overlap = 4, minlen = 3, winlen=0.05, winstep=0.0097, NFFT=840, sr_target=44100):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  y, sr = librosa.load(path, sr=sr_target)\n",
        "  print(f\"shape: {y.shape}\", f'sr: {sr}')\n",
        "  sig_splits = []\n",
        "  step = int((seconds - overlap) * sr)\n",
        "  window_length = int(seconds * sr)\n",
        "  NFFT = max(NFFT, int(winlen * sr))\n",
        "\n",
        "  for i in range(0, len(y), step):\n",
        "    split =  y[i:i + window_length]\n",
        "    if len(split) >= minlen:\n",
        "      sig_splits.append(split)\n",
        "\n",
        "  if len(sig_splits) == 0:\n",
        "    sig_splits.append(sig)\n",
        "\n",
        "\n",
        "  for split_sig in sig_splits:\n",
        "        # compute mel spectrogram\n",
        "        mel_spec = librosa.feature.melspectrogram(\n",
        "            y=split_sig,\n",
        "            sr=sr,\n",
        "            n_fft=int(winlen * sr),\n",
        "            hop_length=int(winstep * sr),\n",
        "            n_mels=128*2\n",
        "        )\n",
        "\n",
        "        # Convert to dB scale\n",
        "        mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "        # resize to fixed shape\n",
        "        mel_spec_resized = cv2.resize(mel_spec_db, (512, 256))\n",
        "\n",
        "        yield mel_spec_resized\n",
        "\n",
        "def filter_isolated_cells(array, struct):\n",
        "\n",
        "    filtered_array = np.copy(array)\n",
        "    id_regions, num_ids = ndimage.label(filtered_array, structure=struct)\n",
        "    id_sizes = np.array(ndimage.sum(array, id_regions, range(num_ids + 1)))\n",
        "    area_mask = (id_sizes == 1)\n",
        "    filtered_array[area_mask[id_regions]] = 0\n",
        "\n",
        "    return filtered_array\n",
        "\n",
        "\n",
        "def hasBird(spec, threshold=16):\n",
        "\n",
        "    #working copy\n",
        "    img = spec.copy()\n",
        "\n",
        "    #STEP 1: Median blur\n",
        "    img = cv2.medianBlur(img,5)\n",
        "\n",
        "    #STEP 2: Median threshold\n",
        "    col_median = np.median(img, axis=0, keepdims=True)\n",
        "    row_median = np.median(img, axis=1, keepdims=True)\n",
        "\n",
        "    img[img < row_median * 3] = 0\n",
        "    img[img < col_median * 4] = 0\n",
        "    img[img > 0] = 1\n",
        "\n",
        "    #STEP 3: Remove singles\n",
        "    img = filter_isolated_cells(img, struct=np.ones((3,3)))\n",
        "\n",
        "    #STEP 4: Morph Closing\n",
        "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5,5), np.float32))\n",
        "\n",
        "    #STEP 5: Frequency crop\n",
        "    img = img[128:-16, :]\n",
        "\n",
        "    #STEP 6: Count columns and rows with signal\n",
        "    #(Note: We only use rows with signal as threshold, but columns might come in handy in other scenarios)\n",
        "\n",
        "    #column has signal?\n",
        "    col_max = np.max(img, axis=0)\n",
        "    col_max = ndimage.morphology.binary_dilation(col_max, iterations=2).astype(col_max.dtype)\n",
        "    cthresh = col_max.sum()\n",
        "\n",
        "    #row has signal?\n",
        "    row_max = np.max(img, axis=1)\n",
        "    row_max = ndimage.morphology.binary_dilation(row_max, iterations=2).astype(row_max.dtype)\n",
        "    rthresh = row_max.sum()\n",
        "\n",
        "    #final threshold\n",
        "    thresh = rthresh\n",
        "\n",
        "    #DBUGB: show?\n",
        "    #print thresh\n",
        "    #cv2.imshow('BIRD?', img)\n",
        "    #cv2.waitKey(-1)\n",
        "\n",
        "    #STEP 7: Apply threshold (Default = 16)\n",
        "    bird = True\n",
        "    if thresh < threshold:\n",
        "        bird = False\n",
        "\n",
        "    return bird, thresh"
      ],
      "metadata": {
        "id": "TBsPc3y0RLyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bird = '/content/drive/MyDrive/F2024/Applied Data Science/Project 3/bird_calls_highest_quality/AmericanRobin/543354.mp3'"
      ],
      "metadata": {
        "id": "M-jAvAheSLWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectrograms = list(getMelSpec(bird))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzmPyV6kRexS",
        "outputId": "f781a560-df17-49b5-f6ba-f72d08c02acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (2840832,) sr: 44100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def spectrograms_to_tensor(spectrograms, device='cuda'):\n",
        "    spectrograms_tensor = torch.tensor(np.array(spectrograms)).unsqueeze(1).float().to(device)\n",
        "    return spectrograms_tensor\n",
        "\n",
        "def predict_from_spectrograms(model, spectrograms, device='cuda'):\n",
        "    spectrograms_tensor = spectrograms_to_tensor(spectrograms, device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(spectrograms_tensor)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "spectrograms = list(getMelSpec(bird))\n",
        "predictions = predict_from_spectrograms(model, spectrograms, device='cuda')\n",
        "\n",
        "\n",
        "print(f'Predictions: {predictions}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95szHjwITZOO",
        "outputId": "ea6c603b-085e-4786-d836-22cb1f6f37f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (2840832,) sr: 44100\n",
            "Predictions: tensor([48, 48,  4,  4,  4,  4,  4,  4,  4, 48, 48, 48, 48,  4, 48,  4,  4,  4,\n",
            "        10, 10, 10, 10, 10, 10, 48, 48, 48, 48, 10, 10, 10, 25, 10, 25, 10, 10,\n",
            "         4,  4,  4,  4, 48, 48,  4, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
            "         4,  4,  4,  4,  4,  4,  4, 10, 10, 10, 10], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "3gOlYf-pTd7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pjB0DhvBTyFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_frequent_species(predictions, class_to_species):\n",
        "    prediction_counts = Counter(predictions.cpu().numpy())\n",
        "\n",
        "    most_frequent_index = prediction_counts.most_common(1)[0][0]\n",
        "    most_frequent_count = prediction_counts.most_common(1)[0][1]\n",
        "\n",
        "    species = class_to_species[most_frequent_index]\n",
        "\n",
        "    confidence = (most_frequent_count / len(predictions)) * 100\n",
        "\n",
        "    return species, confidence, prediction_counts"
      ],
      "metadata": {
        "id": "LTfR-38kT0wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "species, confidence, prediction_counts = get_most_frequent_species(predictions, class_to_species)\n",
        "\n",
        "print(f'Most frequent species: {species} in {confidence:.2f}% of recording')\n",
        "print(f'Prediction counts: {dict(prediction_counts)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnDEmT_JT3Ww",
        "outputId": "2d260cb5-12d0-4490-d860-e2f8de55792f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent species: Dark-eyedJunco in 36.92% of recording\n",
            "Prediction counts: {48: 24, 4: 23, 10: 16, 25: 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OI80IvVtAq9k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
